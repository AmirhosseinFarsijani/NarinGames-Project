{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amirh\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\amirh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection._split import train_test_split\n",
    "from sklearn.feature_selection.univariate_selection import SelectPercentile\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "#algorithms\n",
    "from sklearn.linear_model.stochastic_gradient import SGDClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors.classification import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble.weight_boosting import AdaBoostClassifier\n",
    "from sklearn.ensemble.forest import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.metrics.classification import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>genre</th>\n",
       "      <th>score</th>\n",
       "      <th>score_num</th>\n",
       "      <th>downloads</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lords Mobile: Kingdom Wars</td>\n",
       "      <td>Strategy</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5,946,326</td>\n",
       "      <td>100,000,000+</td>\n",
       "      <td>Are you ready for a REAL fight?\\n\\nThe true Em...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fishdom</td>\n",
       "      <td>Puzzle</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4,565,785</td>\n",
       "      <td>100,000,000+</td>\n",
       "      <td>Never Fishdomed before? Take a deep breath and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>State of Survival: Survive the Zombie Apocalypse</td>\n",
       "      <td>Strategy</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1,522,191</td>\n",
       "      <td>10,000,000+</td>\n",
       "      <td>\"It's been six months since the zombie apocaly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Genshin Impact</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1,060,121</td>\n",
       "      <td>10,000,000+</td>\n",
       "      <td>Step into Teyvat, a vast world teeming with li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gardenscapes</td>\n",
       "      <td>Casual</td>\n",
       "      <td>4.4</td>\n",
       "      <td>10,246,959</td>\n",
       "      <td>100,000,000+</td>\n",
       "      <td>Welcome to Gardenscapes—the first hit from Pla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               name      genre  score  \\\n",
       "0                        Lords Mobile: Kingdom Wars   Strategy    4.3   \n",
       "1                                           Fishdom     Puzzle    4.4   \n",
       "2  State of Survival: Survive the Zombie Apocalypse   Strategy    4.4   \n",
       "3                                    Genshin Impact  Adventure    4.5   \n",
       "4                                      Gardenscapes     Casual    4.4   \n",
       "\n",
       "    score_num     downloads                                        description  \n",
       "0   5,946,326  100,000,000+  Are you ready for a REAL fight?\\n\\nThe true Em...  \n",
       "1   4,565,785  100,000,000+  Never Fishdomed before? Take a deep breath and...  \n",
       "2   1,522,191   10,000,000+  \"It's been six months since the zombie apocaly...  \n",
       "3   1,060,121   10,000,000+  Step into Teyvat, a vast world teeming with li...  \n",
       "4  10,246,959  100,000,000+  Welcome to Gardenscapes—the first hit from Pla...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games = pd.read_json('https://raw.githubusercontent.com/sshmo/crawler/master/games.jl', lines=True)\n",
    "games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 199 entries, 0 to 198\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   name         199 non-null    object \n",
      " 1   genre        199 non-null    object \n",
      " 2   score        199 non-null    float64\n",
      " 3   score_num    199 non-null    object \n",
      " 4   downloads    199 non-null    object \n",
      " 5   description  199 non-null    object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 9.5+ KB\n"
     ]
    }
   ],
   "source": [
    "games.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Are you ready for a REAL fight?\\n\\nThe true Em...</td>\n",
       "      <td>Strategy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Never Fishdomed before? Take a deep breath and...</td>\n",
       "      <td>Puzzle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"It's been six months since the zombie apocaly...</td>\n",
       "      <td>Strategy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Step into Teyvat, a vast world teeming with li...</td>\n",
       "      <td>Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Welcome to Gardenscapes—the first hit from Pla...</td>\n",
       "      <td>Casual</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description      genre\n",
       "0  Are you ready for a REAL fight?\\n\\nThe true Em...   Strategy\n",
       "1  Never Fishdomed before? Take a deep breath and...     Puzzle\n",
       "2  \"It's been six months since the zombie apocaly...   Strategy\n",
       "3  Step into Teyvat, a vast world teeming with li...  Adventure\n",
       "4  Welcome to Gardenscapes—the first hit from Pla...     Casual"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games = games[[ \"description\", \"genre\"]]\n",
    "games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>readi real fight true emperor fallen need real...</td>\n",
       "      <td>Strategy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>never fishdom take deep breath dive underwat w...</td>\n",
       "      <td>Puzzle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>six month sinc zombi apocalyps began viru infe...</td>\n",
       "      <td>Strategy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>step teyvat vast world teem life flow element ...</td>\n",
       "      <td>Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>welcom gardenscapesth first hit playrix scape ...</td>\n",
       "      <td>Casual</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description      genre\n",
       "0  readi real fight true emperor fallen need real...   Strategy\n",
       "1  never fishdom take deep breath dive underwat w...     Puzzle\n",
       "2  six month sinc zombi apocalyps began viru infe...   Strategy\n",
       "3  step teyvat vast world teem life flow element ...  Adventure\n",
       "4  welcom gardenscapesth first hit playrix scape ...     Casual"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text preprocessing\n",
    "\n",
    "for index, row in games.iterrows():\n",
    "    text = row['description']\n",
    "    # 1.lowercase\n",
    "    text_lower = text.lower()\n",
    "    ## 2.Removing Punctuation and unicode chars\n",
    "    text_lower_unicode = \"\".join([char for char in text_lower if char not in string.punctuation])\n",
    "    text_lower_unicode = text_lower_unicode.encode('ascii', 'ignore').decode()\n",
    "    ### 3.Tokenization\n",
    "    text_lower_unicode_tokenized = word_tokenize(text_lower_unicode)\n",
    "    #### 4.Stopword Filtering\n",
    "    text_lower_unicode_tokenized_filtered = [w for w in text_lower_unicode_tokenized if not w in stopwords.words('english')]\n",
    "    ##### 5.Stemming\n",
    "    porter = PorterStemmer()\n",
    "    text_lower_unicode_tokenized_filtered_stemming = [porter.stem(w) for w in text_lower_unicode_tokenized_filtered]\n",
    "    ###### 6.add to DataFrame\n",
    "    games.loc[index] = {'description': ' '.join(text_lower_unicode_tokenized_filtered_stemming), 'genre': row['genre']}\n",
    "    \n",
    "games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199, 5548)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5)\n",
    "X = vectorizer.fit(games['description']).transform(games['description'])\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label encoder\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit(games['genre']).transform(games['genre'])\n",
    "np.unique(games['genre'])\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Elimination\n",
    "\n",
    "#ch2 = SelectPercentile(chi2, 80)\n",
    "#X_train = ch2.fit_transform(X_train, y_train)\n",
    "#X_test = ch2.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDG score: 0.58\n"
     ]
    }
   ],
   "source": [
    "#np.random.seed(42)\n",
    "# algoritms\n",
    "\n",
    "# 1.SGDClassifier max : 74 --> seed : 23\n",
    "np.random.seed(23)\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, y_train)\n",
    "score = sgd.score(X_test, y_test)\n",
    "print('SDG score: ' + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm score: 0.34\n"
     ]
    }
   ],
   "source": [
    "## 2.SVC max : 0.3 --> seed : *\n",
    "\n",
    "svmc = svm.SVC()\n",
    "svmc.fit(X_train, y_train)\n",
    "score = svmc.score(X_test, y_test)\n",
    "print('svm score: ' + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm linear score: 0.56\n"
     ]
    }
   ],
   "source": [
    "## 2.1SVC max : 0.72 --> seed : *\n",
    "\n",
    "svmlc = svm.SVC(kernel='linear', C=1.2)\n",
    "svmlc.fit(X_train, y_train)\n",
    "score = svmlc.score(X_test, y_test)\n",
    "print('svm linear score: ' + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn score: 0.58\n"
     ]
    }
   ],
   "source": [
    "### 3.KNNClassifier max : 0.68 --> seed : *\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "score = knn.score(X_test, y_test)\n",
    "print('knn score: ' + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn2 score: 0.62\n"
     ]
    }
   ],
   "source": [
    "### 3.1KNNClassifier max : 0.66 --> seed : *\n",
    "\n",
    "knn2 = KNeighborsClassifier(n_neighbors=6, weights='distance')\n",
    "knn2.fit(X_train, y_train)\n",
    "score = knn2.score(X_test, y_test)\n",
    "print('knn2 score: ' + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnnb score: 0.36\n"
     ]
    }
   ],
   "source": [
    "#### 4.MultinomialNB max : 0.3 --> seed : *\n",
    "\n",
    "mnnb = MultinomialNB()\n",
    "mnnb.fit(X_train, y_train)\n",
    "score = mnnb.score(X_test, y_test)\n",
    "print('mnnb score: ' + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc score: 0.26\n"
     ]
    }
   ],
   "source": [
    "##### 5.AdaBoost Classsifier max : 0.3 --> seed : 23\n",
    "np.random.seed(23)\n",
    "\n",
    "abc = AdaBoostClassifier()\n",
    "abc.fit(X_train, y_train)\n",
    "score = abc.score(X_test, y_test)\n",
    "print('abc score: ' + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc2 score: 0.24\n"
     ]
    }
   ],
   "source": [
    "##### 5.1AdaBoost Classsifier max : 0.3 --> seed : 23\n",
    "np.random.seed(23)\n",
    "\n",
    "abc2 = AdaBoostClassifier(n_estimators=100)\n",
    "abc2.fit(X_train, y_train)\n",
    "score = abc2.score(X_test, y_test)\n",
    "print('abc2 score: ' + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc score: 0.5\n"
     ]
    }
   ],
   "source": [
    "###### 6.RandomForest Classifier max : 0.62 --> seed : 12\n",
    "np.random.seed(12)\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "score = rfc.score(X_test, y_test)\n",
    "print('rfc score: ' + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc2 score: 0.48\n"
     ]
    }
   ],
   "source": [
    "###### 6.1RandomForest Classifier max : 0.72 --> seed : 93\n",
    "np.random.seed(93)\n",
    "\n",
    "rfc2 = RandomForestClassifier(n_estimators=163)\n",
    "rfc2.fit(X_train, y_train)\n",
    "score = rfc2.score(X_test, y_test)\n",
    "print('rfc2 score: ' + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vcls score: 0.6\n"
     ]
    }
   ],
   "source": [
    "####### 7.Voting Classifier max : 0.7 --> seed : 41\n",
    "np.random.seed(41)\n",
    "\n",
    "vcls = VotingClassifier(estimators=[('randomforest', rfc2), ('naivebayes', mnnb), ('knn', knn), ('svm', svmlc)])\n",
    "vcls.fit(X_train, y_train)\n",
    "score = vcls.score(X_test, y_test)\n",
    "print('vcls score: ' + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnnb score: 0.64\n"
     ]
    }
   ],
   "source": [
    "######## 8.MultinomialNB\n",
    "\n",
    "mnnb = MultinomialNB(alpha=0.01, fit_prior=True)\n",
    "mnnb.fit(X_train, y_train)\n",
    "score = mnnb.score(X_test, y_test)\n",
    "print('mnnb score: ' + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnnb recal: 0.563860498475883\n",
      "mnnb precision: 0.5583826429980276\n",
      "mnnb f1: 0.5358551704705551\n",
      "mnnb confusion matrix: \n",
      "[[2 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 3 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 2 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 3 0 0 1 0 0]\n",
      " [1 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [2 0 0 0 0 0 0 0 0 5 0 0 4]\n",
      " [0 0 0 0 0 0 1 0 0 0 2 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 3 0]\n",
      " [2 0 0 0 0 0 1 0 1 0 0 0 9]]\n"
     ]
    }
   ],
   "source": [
    "mnnb_predict = mnnb.predict(X_test)\n",
    "mnnb_recall = recall_score(y_test, mnnb_predict, average='macro')\n",
    "mnnb_precision = precision_score(y_test, mnnb_predict, average='macro')\n",
    "mnnb_f1 = f1_score(y_test, mnnb_predict, average='macro')\n",
    "mnnb_conf = confusion_matrix(y_test, mnnb_predict)\n",
    "print(\"mnnb recal: \" + str(mnnb_recall))\n",
    "print(\"mnnb precision: \" + str(mnnb_precision))\n",
    "print(\"mnnb f1: \" + str(mnnb_f1))\n",
    "print(\"mnnb confusion matrix: \\n\" + str(mnnb_conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vcls recal: 0.5168220668220668\n",
      "vcls precision: 0.5986111111111111\n",
      "vcls f1: 0.49419002050581\n",
      "vcls confusion matrix: \n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  2]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  1  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  3  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  3  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  3  2  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  6  0  0  4]\n",
      " [ 0  0  0  0  0  1  0  0  0  1  0  1]\n",
      " [ 0  0  0  0  0  2  0  0  2  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0 12]]\n"
     ]
    }
   ],
   "source": [
    "vcls_predict = vcls.predict(X_test)\n",
    "vcls_recall = recall_score(y_test, vcls_predict, average='macro')\n",
    "vcls_precision = precision_score(y_test, vcls_predict, average='macro')\n",
    "vcls_f1 = f1_score(y_test, vcls_predict, average='macro')\n",
    "vcls_conf = confusion_matrix(y_test, vcls_predict)\n",
    "print(\"vcls recal: \" + str(vcls_recall))\n",
    "print(\"vcls precision: \" + str(vcls_precision))\n",
    "print(\"vcls f1: \" + str(vcls_f1))\n",
    "print(\"vcls confusion matrix: \\n\" + str(vcls_conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn recal: 0.5259817105970952\n",
      "knn precision: 0.4756410256410256\n",
      "knn f1: 0.48369963369963376\n",
      "svmlc confusion matrix: \n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 2]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 3 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 2 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 3 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
      " [2 0 0 0 0 0 0 0 0 6 0 0 3]\n",
      " [0 0 0 0 0 0 1 0 0 1 1 0 0]\n",
      " [0 0 0 0 1 1 0 0 1 1 0 0 0]\n",
      " [2 0 0 0 0 0 0 0 1 1 0 0 9]]\n"
     ]
    }
   ],
   "source": [
    "knn_predict = knn.predict(X_test)\n",
    "knn_recall = recall_score(y_test, knn_predict, average='macro')\n",
    "knn_precision = precision_score(y_test, knn_predict, average='macro')\n",
    "knn_f1 = f1_score(y_test, knn_predict, average='macro')\n",
    "knn_conf = confusion_matrix(y_test, knn_predict)\n",
    "print(\"knn recal: \" + str(knn_recall))\n",
    "print(\"knn precision: \" + str(knn_precision))\n",
    "print(\"knn f1: \" + str(knn_f1))\n",
    "print(\"svmlc confusion matrix: \\n\" + str(knn_conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn2 recal: 0.551129639591178\n",
      "knn2 precision: 0.5324283559577677\n",
      "knn2 f1: 0.5238577212261423\n",
      "knn2 confusion matrix: \n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  2]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  2  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  3  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  2  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  3  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  2  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  6  0  0  4]\n",
      " [ 0  0  0  0  0  0  1  0  0  1  1  0  0]\n",
      " [ 0  0  0  0  1  1  0  0  0  1  0  1  0]\n",
      " [ 1  0  0  0  0  0  0  0  1  0  0  1 10]]\n"
     ]
    }
   ],
   "source": [
    "knn2_predict = knn2.predict(X_test)\n",
    "knn2_recall = recall_score(y_test, knn2_predict, average='macro')\n",
    "knn2_precision = precision_score(y_test, knn2_predict, average='macro')\n",
    "knn2_f1 = f1_score(y_test, knn2_predict, average='macro')\n",
    "knn2_conf = confusion_matrix(y_test, knn2_predict)\n",
    "print(\"knn2 recal: \" + str(knn2_recall))\n",
    "print(\"knn2 precision: \" + str(knn2_precision))\n",
    "print(\"knn2 f1: \" + str(knn2_f1))\n",
    "print(\"knn2 confusion matrix: \\n\" + str(knn2_conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svmlc recal: 0.44459984459984464\n",
      "svmlc precision: 0.4152777777777777\n",
      "svmlc f1: 0.37114362245941196\n",
      "svmlc confusion matrix: \n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  2]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  1  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  3  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  3  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  3  1  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 1  0  0  0  0  0  0  0  6  0  0  4]\n",
      " [ 0  0  0  0  0  1  0  0  0  2  0  0]\n",
      " [ 0  0  0  0  0  2  0  0  2  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0 12]]\n"
     ]
    }
   ],
   "source": [
    "svmlc_predict = svmlc.predict(X_test)\n",
    "svmlc_recall = recall_score(y_test, svmlc_predict, average='macro')\n",
    "svmlc_precision = precision_score(y_test, svmlc_predict, average='macro')\n",
    "svmlc_f1 = f1_score(y_test, svmlc_predict, average='macro')\n",
    "svmlc_conf = confusion_matrix(y_test, svmlc_predict)\n",
    "print(\"svmlc recal: \" + str(svmlc_recall))\n",
    "print(\"svmlc precision: \" + str(svmlc_precision))\n",
    "print(\"svmlc f1: \" + str(svmlc_f1))\n",
    "print(\"svmlc confusion matrix: \\n\" + str(svmlc_conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model\n",
    "import pickle\n",
    "\n",
    "filename = 'naringame_ML_genre_model.sav'\n",
    "pickle.dump(mnnb, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load model\n",
    "### some times later ...\n",
    "\n",
    "#loaded_model = pickle.load(open(filename, 'rb'))\n",
    "#result = loaded_model.score(X_test, Y_test)\n",
    "#print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
